{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "We have a dataset from BBC news with data of about 2000 news articles. The dataset is categorized into five different categories of tech, business, entertainment, politics and sports. The task is to build a model which can predict the category of the news article. This is a multi-class classification problem\n",
    "\n",
    "The task is accompolished using three key things. First, we clean the textual data using different NLP guidelines, then we apply TF-IDF vectorizer to understand the importance of words present in news article relative to all the other articles. Then we provide these TF-IDF features to different classifiers to see which of these get us the highest accuracy in predicting the category of the news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bbc-text.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>tech</td>\n",
       "      <td>gadgets galore on show at fair the 2005 consum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>tech</td>\n",
       "      <td>no half measures with half-life 2 could half-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>sport</td>\n",
       "      <td>minister digs in over doping row the belgian s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>sport</td>\n",
       "      <td>bees handed potential man utd tie brentford fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair backs  pre-election budget  tony blair h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                               text\n",
       "615       tech  gadgets galore on show at fair the 2005 consum...\n",
       "1904      tech  no half measures with half-life 2 could half-l...\n",
       "734      sport  minister digs in over doping row the belgian s...\n",
       "1434     sport  bees handed potential man utd tie brentford fa...\n",
       "431   politics  blair backs  pre-election budget  tony blair h..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Data Cleaning\n",
    "1. Keep only ascii characters\n",
    "2. Remove numbers from the text\n",
    "3. Remove stopwords\n",
    "4. Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_cleaning( raw_text ):\n",
    "    ## non ascii characters\n",
    "    letters_only = re.sub(r'[^\\x00-\\x7F]+',' ', raw_text)\n",
    "    letters_only = re.sub('[0-9]', '', letters_only)\n",
    "    \n",
    "    #convert to lower case, split into individual words\n",
    "    words = [letters_only.lower().strip()]\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return ' '.join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(words_cleaning)\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>sport</td>\n",
       "      <td>england given tough sevens draw england will h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>sport</td>\n",
       "      <td>scrumhalf williams rejoins bath bath have sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>business</td>\n",
       "      <td>jarvis sells tube stake to spain shares in eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>business</td>\n",
       "      <td>huge rush for jet airways shares indian airlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tech</td>\n",
       "      <td>consumers  snub portable video  consumers want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                               text\n",
       "609      sport  england given tough sevens draw england will h...\n",
       "957      sport  scrumhalf williams rejoins bath bath have sign...\n",
       "1759  business  jarvis sells tube stake to spain shares in eng...\n",
       "1949  business  huge rush for jet airways shares indian airlin...\n",
       "282       tech  consumers  snub portable video  consumers want..."
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the textual data to get TF-IDF features\n",
    "TF-IDF term frequencyâ€“inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus\n",
    "\n",
    "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "\n",
    "<b> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).</b>\n",
    "\n",
    "IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "<b>IDF(t) = log_e(Total number of documents / Number of documents with term t in it).</b>\n",
    "\n",
    "<b>TF-IDF = TF * IDF</b>\n",
    "\n",
    "We apply TF-IDF on the data which converts all words to lowercase, removes stopwords and ignores rare words which appear less than 3% in the complete list of news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 988)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 1), min_df=0.03)\n",
    "tfidf_features = tfidf_vec.fit_transform(df['text'])\n",
    "tfidf_df = pd.DataFrame(tfidf_features.todense(), columns=tfidf_vec.get_feature_names())\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accused</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worldwide</th>\n",
       "      <th>worth</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196587</td>\n",
       "      <td>0.097903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 988 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability      able    access  according  account  accounts   accused  \\\n",
       "2155      0.0  0.000000  0.000000        0.0      0.0       0.0  0.196587   \n",
       "1342      0.0  0.112511  0.000000        0.0      0.0       0.0  0.000000   \n",
       "1695      0.0  0.000000  0.074854        0.0      0.0       0.0  0.000000   \n",
       "1014      0.0  0.160883  0.000000        0.0      0.0       0.0  0.000000   \n",
       "1471      0.0  0.000000  0.000000        0.0      0.0       0.0  0.000000   \n",
       "\n",
       "           act    action  actor  ...    world  worldwide  worth  written  \\\n",
       "2155  0.097903  0.000000    0.0  ...      0.0        0.0    0.0      0.0   \n",
       "1342  0.000000  0.000000    0.0  ...      0.0        0.0    0.0      0.0   \n",
       "1695  0.000000  0.065477    0.0  ...      0.0        0.0    0.0      0.0   \n",
       "1014  0.000000  0.000000    0.0  ...      0.0        0.0    0.0      0.0   \n",
       "1471  0.000000  0.000000    0.0  ...      0.0        0.0    0.0      0.0   \n",
       "\n",
       "      wrong      year   yearold     years  york  young  \n",
       "2155    0.0  0.000000  0.000000  0.000000   0.0    0.0  \n",
       "1342    0.0  0.000000  0.112511  0.000000   0.0    0.0  \n",
       "1695    0.0  0.108084  0.000000  0.044008   0.0    0.0  \n",
       "1014    0.0  0.000000  0.000000  0.000000   0.0    0.0  \n",
       "1471    0.0  0.000000  0.000000  0.000000   0.0    0.0  \n",
       "\n",
       "[5 rows x 988 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 989)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df['category'] = df['category']\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "tfidf_df['category'] = le.fit_transform(tfidf_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different classifiers on TF-IDF data to predict the category\n",
    "1. Split the data into train and test\n",
    "2. Create a helper function to train the model and calculate the accuracy\n",
    "3. Train following classifiers -<br>\n",
    "    1. Decision Tree\n",
    "    2. Bagging based Random Forest\n",
    "    3. Boosting based XGBoost\n",
    "    4. Naive Bayes\n",
    "    5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df.drop(['category'], axis=1), tfidf_df['category'],\\\n",
    "                                                    test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(y_train, y_train_pred))\n",
    "    print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8202247191011236\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "analyze_model(dt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998876404494382\n",
      "0.8966292134831461\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "analyze_model(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996629213483146\n",
      "0.9325842696629213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(random_state=42)\n",
    "analyze_model(xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9691011235955056\n",
      "0.9303370786516854\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "analyze_model(nb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9882022471910112\n",
      "0.946067415730337\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(random_state=42)\n",
    "analyze_model(log_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
